# -*- coding: utf-8 -*-
"""AIPowered Music Sentiment Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GziG3rru0TarIH_sVYsWjOLmaTp_UCKw
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing libraries and setting up the plotting configuration
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd

import matplotlib
matplotlib.use('Agg')  # For environments that require non-interactive backend
import matplotlib.pyplot as plt
plt.switch_backend('Agg')  # Ensure proper backend switching when only plt is imported

import seaborn as sns

# For inline plotting on Kaggle
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

sns.set(style='whitegrid', context='notebook')

# Load the dataset
data_path = '/kaggle/input/ai-powered-music-recommendation-system/music_sentiment_dataset.csv'
df = pd.read_csv(data_path, encoding='ascii', delimiter=',')

# Display the first few rows of the dataframe
df.head()

from google.colab import files
uploaded = files.upload()

# Load the dataset
#data_path = '# Load the dataset
data_path = 'music_sentiment_dataset.csv'
df = pd.read_csv(data_path, encoding='ascii', delimiter=',')

# Display the first few rows of the dataframe
df.head()
df = pd.read_csv(data_path, encoding='ascii', delimiter=',')

# Display the first few rows of the dataframe
df.head()

# Check for missing values and basic data info
print(df.info())
print(df.isnull().sum())

# In case there are missing values, especially in critical columns, we will handle them appropriately
# For this example, we'll drop rows with missing target 'Sentiment_Label' or any essential features
essential_columns = ['Sentiment_Label', 'Tempo (BPM)', 'Genre', 'Mood', 'Energy', 'Danceability']
df.dropna(subset=essential_columns, inplace=True)

# Convert 'Tempo (BPM)' to numeric (if not already) and force errors to NaN for further cleaning
df['Tempo (BPM)'] = pd.to_numeric(df['Tempo (BPM)'], errors='coerce')

# After conversion, drop rows with NaN in 'Tempo (BPM)'
df.dropna(subset=['Tempo (BPM)'], inplace=True)

# Reset index after dropping rows
df.reset_index(drop=True, inplace=True)

# Display summary statistics for numeric columns
df.describe()

## Count Plot for Sentiment Labels
plt.figure(figsize=(10,6))
sns.countplot(data=df, x='Sentiment_Label', palette='viridis')
plt.title('Distribution of Sentiment Labels')
plt.xlabel('Sentiment Label')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

## Histogram for Tempo (BPM)
plt.figure(figsize=(10,6))
sns.histplot(data=df, x='Tempo (BPM)', kde=True, color='c')
plt.title('Distribution of Tempo (BPM)')
plt.xlabel('Tempo (BPM)')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

## Box Plot of Tempo (BPM) grouped by Sentiment Label
plt.figure(figsize=(10,6))
sns.boxplot(data=df, x='Sentiment_Label', y='Tempo (BPM)', palette='Set3')
plt.title('Tempo (BPM) Distribution by Sentiment Label')
plt.xlabel('Sentiment Label')
plt.ylabel('Tempo (BPM)')
plt.tight_layout()
plt.show()

## Count Plot for Genre
plt.figure(figsize=(12,6))
sns.countplot(data=df, x='Genre', palette='coolwarm', order=df['Genre'].value_counts().index)
plt.title('Distribution of Music Genres')
plt.xlabel('Genre')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# For predictive modeling, we aim to predict the 'Sentiment_Label'.
# We will use a simple RandomForestClassifier, after encoding categorical features.

# Selecting relevant features for prediction.
# Exclude columns that are unlikely to be useful predictors such as IDs and textual descriptions
features = ['Tempo (BPM)', 'Genre', 'Mood', 'Energy', 'Danceability']
target = 'Sentiment_Label'

# Make a copy of the dataframe for modeling
model_df = df[features + [target]].copy()

# Encode categorical variables. For simplicity, we use LabelEncoder for target, and pd.get_dummies for features
# Encoding target variable
le = LabelEncoder()
model_df[target] = le.fit_transform(model_df[target])

# One-hot encode categorical features: Genre, Mood, Energy, Danceability
categorical_features = ['Genre', 'Mood', 'Energy', 'Danceability']
model_df = pd.get_dummies(model_df, columns=categorical_features, drop_first=True)

# Split the data into training and testing sets
X = model_df.drop(target, axis=1)
y = model_df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions and evaluate
y_pred = rf_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy of the RandomForest model: {accuracy:.4f}')

print('\nClassification Report:\n')
print(classification_report(y_test, y_pred))

# Plotting the Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

# Permutation Importance visualization
importances = rf_model.feature_importances_
indices = np.argsort(importances)
feature_names = X.columns

plt.figure(figsize=(10,6))
plt.barh(range(len(indices)), importances[indices], color='teal', align='center')
plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
plt.xlabel('Relative Importance')
plt.title('Permutation Importance of Features')
plt.tight_layout()
plt.show()

